"""
üß† LLM Client - –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback
–ü–æ–¥–¥–µ—Ä–∂–∫–∞: OpenAI, DeepSeek, xAI Grok, Google Gemini, Cohere, HuggingFace
"""

import requests
from typing import Optional, List, Dict, Any
from config import Config
import logging

logger = logging.getLogger(__name__)


class LLMProvider:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
    
    def __init__(self, name: str, api_key: str, model: str):
        self.name = name
        self.api_key = api_key
        self.model = model
        self.is_available = bool(api_key)
    
    def generate(self, prompt: str, system_prompt: str = "", temperature: float = 0.7, max_tokens: int = 1000) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω –≤ –Ω–∞—Å–ª–µ–¥–Ω–∏–∫–∞—Ö)"""
        raise NotImplementedError


class OpenAIProvider(LLMProvider):
    """OpenAI / DeepSeek / xAI / Groq (OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ API)"""
    
    def __init__(self, name: str, api_key: str, model: str, base_url: Optional[str] = None):
        super().__init__(name, api_key, model)
        self.base_url = base_url
        if self.is_available:
            try:
                from openai import OpenAI
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å base_url
                if base_url:
                    self.client = OpenAI(
                        api_key=api_key,
                        base_url=base_url,
                        timeout=30.0  # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç
                    )
                else:
                    self.client = OpenAI(
                        api_key=api_key,
                        timeout=30.0
                    )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è {name}: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç: {e}")
                self.is_available = False
    
    def generate(self, prompt: str, system_prompt: str = "", temperature: float = 0.7, max_tokens: int = 1000) -> Optional[str]:
        try:
            messages = []
            if system_prompt:
                messages.append({"role": "system", "content": system_prompt})
            messages.append({"role": "user", "content": prompt})
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {self.name}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None


class GoogleGeminiProvider(LLMProvider):
    """Google AI Studio (Gemini)"""
    
    def __init__(self, name: str, api_key: str, model: str = "gemini-1.5-flash"):
        super().__init__(name, api_key, model)
        if self.is_available:
            try:
                import google.generativeai as genai
                genai.configure(api_key=api_key)
                # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å models/ –µ—Å–ª–∏ –µ—Å—Ç—å
                clean_model = model.replace("models/", "")
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: generation_config –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏, –∞ –Ω–µ –≤ generate_content
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã, —Ç.–∫. temperature –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å—Å—è –≤ generate()
                self.client = genai.GenerativeModel(clean_model)
                self.genai = genai  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —Ä–∞–∑–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è {name}: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç: {e}")
                self.is_available = False
    
    def generate(self, prompt: str, system_prompt: str = "", temperature: float = 0.7, max_tokens: int = 1000) -> Optional[str]:
        try:
            # Gemini –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π system prompt, –∫–æ–º–±–∏–Ω–∏—Ä—É–µ–º
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å —Å generation_config –ø—Ä–∏ –∫–∞–∂–¥–æ–º –≤—ã–∑–æ–≤–µ
            model_with_config = self.genai.GenerativeModel(
                model_name=self.model,
                generation_config={
                    "temperature": temperature,
                    "max_output_tokens": max_tokens,
                }
            )
            
            # –í—ã–∑—ã–≤–∞–µ–º generate_content –ë–ï–ó generation_config
            response = model_with_config.generate_content(full_prompt)
            return response.text.strip()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {self.name}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None


class CohereProvider(LLMProvider):
    """Cohere AI"""
    
    def __init__(self, name: str, api_key: str, model: str = "command-r-plus"):
        super().__init__(name, api_key, model)
        if self.is_available:
            try:
                import cohere
                self.client = cohere.Client(api_key)
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è {name}: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç: {e}")
                self.is_available = False
    
    def generate(self, prompt: str, system_prompt: str = "", temperature: float = 0.7, max_tokens: int = 1000) -> Optional[str]:
        try:
            # Cohere –∏—Å–ø–æ–ª—å–∑—É–µ—Ç preamble –¥–ª—è system prompt
            preamble = system_prompt if system_prompt else None
            
            response = self.client.chat(
                message=prompt,
                preamble=preamble,
                model=self.model,
                temperature=temperature,
                max_tokens=max_tokens
            )
            return response.text.strip()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {self.name}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None


class HuggingFaceProvider(LLMProvider):
    """HuggingFace Inference API"""
    
    def __init__(self, name: str, api_key: str, model: str = "mistralai/Mixtral-8x7B-Instruct-v0.1"):
        super().__init__(name, api_key, model)
        self.api_url = f"https://api-inference.huggingface.co/models/{model}"
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –î–æ–±–∞–≤–ª—è–µ–º Content-Type –≤ headers
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
    
    def generate(self, prompt: str, system_prompt: str = "", temperature: float = 0.7, max_tokens: int = 1000) -> Optional[str]:
        try:
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –∫–∞–∫ —Å—Ç—Ä–æ–∫—É (inputs –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å—Ç—Ä–æ–∫–æ–π, –Ω–µ –º–∞—Å—Å–∏–≤–æ–º)
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            
            payload = {
                "inputs": full_prompt,  # –£–±–µ–¥–∏–º—Å—è —á—Ç–æ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞
                "parameters": {
                    "temperature": temperature,
                    "max_new_tokens": max_tokens,
                    "return_full_text": False,
                    "do_sample": True  # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –ª—É—á—à–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                }
            }
            
            response = requests.post(
                self.api_url,
                headers=self.headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –æ—Ç–≤–µ—Ç–∞
                if isinstance(result, list) and len(result) > 0:
                    # –§–æ—Ä–º–∞—Ç: [{"generated_text": "..."}]
                    generated = result[0].get("generated_text", "").strip()
                    if generated:
                        return generated
                    logger.warning(f"‚ö†Ô∏è {self.name}: –ü—É—Å—Ç–æ–π generated_text –≤ –æ—Ç–≤–µ—Ç–µ")
                elif isinstance(result, dict) and "generated_text" in result:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: {"generated_text": "..."}
                    generated = result["generated_text"].strip()
                    if generated:
                        return generated
                else:
                    logger.warning(f"‚ö†Ô∏è {self.name}: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {result}")
            else:
                logger.warning(f"‚ö†Ô∏è {self.name}: HTTP {response.status_code}: {response.text[:200]}")
            return None
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è {self.name}: –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            return None


class LLMClient:
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏"""
    
    def __init__(self):
        self.temperature = Config.LLM_TEMPERATURE
        self.providers: List[LLMProvider] = []
        self.current_provider_index = 0
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        self._initialize_providers()
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–æ—Å—Ç—É–ø–Ω—ã–µ
        self.providers = [p for p in self.providers if p.is_available]
        
        if not self.providers:
            logger.warning("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ë–æ—Ç –±—É–¥–µ—Ç –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Å—Ç—ã –ë–ï–ó AI –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
            logger.warning("‚ö†Ô∏è –î–ª—è AI –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ø–æ–ª–Ω–∏—Ç–µ DeepSeek: https://platform.deepseek.com")
        else:
            logger.info(f"‚úÖ –î–æ—Å—Ç—É–ø–Ω—ã–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {[p.name for p in self.providers]}")
    
    def _initialize_providers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        
        # –ê–ö–¢–£–ê–õ–¨–ù–´–ï –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–æ–∫—Ç—è–±—Ä—å 2025)
        default_models = {
            "deepseek": "deepseek-chat",
            "groq": "llama-3.1-8b-instant",  # ‚úÖ –†–ê–ë–û–¢–ê–ï–¢!
            "google": "gemini-pro",  # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è (–±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ models/)
            "huggingface": "google/flan-t5-base",  # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –±–µ—Å–ø–ª–∞—Ç–Ω–∞—è –º–æ–¥–µ–ª—å Google
            "xai": "grok-beta"  # xAI Grok –º–æ–¥–µ–ª—å
        }
        
        use_custom_model = Config.LLM_MODEL != 'auto' and Config.LLM_PROVIDER != 'auto'
        
        # GROQ - –ë–ï–°–ü–õ–ê–¢–ù–û, –±—ã—Å—Ç—Ä–æ! (groq.com)
        if hasattr(Config, 'GROQ_API_KEY') and Config.GROQ_API_KEY:
            model = Config.LLM_MODEL if (use_custom_model and Config.LLM_PROVIDER == 'groq') else default_models["groq"]
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π base_url –¥–ª—è Groq
            provider = OpenAIProvider("Groq", Config.GROQ_API_KEY, model, "https://api.groq.com/openai/v1")
            if self._test_provider(provider):
                self.providers.append(provider)
        
        # Google Gemini - –ë–ï–°–ü–õ–ê–¢–ù–û 60 req/min
        if hasattr(Config, 'GOOGLE_API_KEY') and Config.GOOGLE_API_KEY:
            model = Config.LLM_MODEL if (use_custom_model and Config.LLM_PROVIDER == 'google') else default_models["google"]
            provider = GoogleGeminiProvider("Google Gemini", Config.GOOGLE_API_KEY, model)
            if self._test_provider(provider):
                self.providers.append(provider)
        
        # HuggingFace - –ë–ï–°–ü–õ–ê–¢–ù–û
        if hasattr(Config, 'HUGGINGFACE_API_KEY') and Config.HUGGINGFACE_API_KEY:
            model = Config.LLM_MODEL if (use_custom_model and Config.LLM_PROVIDER == 'huggingface') else default_models["huggingface"]
            provider = HuggingFaceProvider("HuggingFace", Config.HUGGINGFACE_API_KEY, model)
            if self._test_provider(provider):
                self.providers.append(provider)
        
        # DeepSeek - –¥–µ—à–µ–≤–æ ($0.14/1M), –µ—Å–ª–∏ –µ—Å—Ç—å –±–∞–ª–∞–Ω—Å
        if hasattr(Config, 'DEEPSEEK_API_KEY') and Config.DEEPSEEK_API_KEY:
            model = Config.LLM_MODEL if (use_custom_model and Config.LLM_PROVIDER == 'deepseek') else default_models["deepseek"]
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π base_url –¥–ª—è DeepSeek (—Å /v1)
            provider = OpenAIProvider("DeepSeek", Config.DEEPSEEK_API_KEY, model, "https://api.deepseek.com/v1")
            if self._test_provider(provider):
                self.providers.append(provider)
        
        # xAI Grok - –ø–ª–∞—Ç–Ω–æ, –µ—Å–ª–∏ –µ—Å—Ç—å –±–∞–ª–∞–Ω—Å
        if hasattr(Config, 'XAI_API_KEY') and Config.XAI_API_KEY:
            model = Config.LLM_MODEL if (use_custom_model and Config.LLM_PROVIDER == 'xai') else default_models["xai"]
            # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π base_url –¥–ª—è xAI
            provider = OpenAIProvider("xAI Grok", Config.XAI_API_KEY, model, "https://api.x.ai/v1")
            if self._test_provider(provider):
                self.providers.append(provider)
    
    def _test_provider(self, provider: LLMProvider) -> bool:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø—Ä–æ—Å—Ç—ã–º –∑–∞–ø—Ä–æ—Å–æ–º"""
        try:
            logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {provider.name}...")
            test_result = provider.generate(
                "Say 'OK' if you work",
                "",
                0.1,
                10
            )
            if test_result and len(test_result.strip()) > 0:
                logger.info(f"‚úÖ {provider.name}: –†–ê–ë–û–¢–ê–ï–¢")
                return True
            else:
                logger.warning(f"‚ùå {provider.name}: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False
        except Exception as e:
            logger.warning(f"‚ùå {provider.name}: –Ω–µ –ø—Ä–æ—à–µ–ª —Ç–µ—Å—Ç ({str(e)[:100]})")
            return False
    
    def _generate_with_fallback(self, prompt: str, system_prompt: str = "", temperature: float = None, max_tokens: int = 1000) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ–º –º–µ–∂–¥—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏"""
        if temperature is None:
            temperature = self.temperature
        
        # –ü—Ä–æ–±—É–µ–º –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ –æ—á–µ—Ä–µ–¥–∏
        for i, provider in enumerate(self.providers):
            logger.info(f"ü§ñ –ü–æ–ø—ã—Ç–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ {provider.name} (–º–æ–¥–µ–ª—å: {provider.model})...")
            result = provider.generate(prompt, system_prompt, temperature, max_tokens)
            
            if result:
                logger.info(f"‚úÖ {provider.name}: –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Ç–µ–∫—Å—Ç")
                # –ü–µ—Ä–µ—Å—Ç–∞–≤–ª—è–µ–º —É—Å–ø–µ—à–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–∞ –ø–µ—Ä–≤–æ–µ –º–µ—Å—Ç–æ –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–∞–∑–∞
                if i > 0:
                    self.providers[0], self.providers[i] = self.providers[i], self.providers[0]
                return result
            else:
                logger.warning(f"‚ö†Ô∏è {provider.name}: –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â–∏–π...")
        
        logger.error("‚ùå –í—Å–µ LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã!")
        return None
    
   def rewrite_text(self, original_text: str, has_links: bool = True) -> str:
    """
    –ü–µ—Ä–µ–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞, –¥–µ–ª–∞—è –µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º
    
    Args:
        original_text: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
        has_links: –ï—Å—Ç—å –ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ —Å—Å—ã–ª–∫–∏ –¥–ª—è –∑–∞–º–µ–Ω—ã
        
    Returns:
        –ü–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω—ã–π —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    """
    try:
        if not original_text or len(original_text.strip()) < 10:
            return original_text
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –Ω–∞–ª–∏—á–∏—è —Å—Å—ã–ª–æ–∫
        if has_links:
            prompt = self._build_rewrite_prompt_with_links(original_text)
        else:
            prompt = self._build_rewrite_prompt_simple(original_text)
        
        system_prompt = "–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π SMM-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞—Ç—å –ø–æ—Å—Ç—ã –Ω–∞ –ª—é–±—ã–µ —Ç–µ–º—ã, —Å–æ—Ö—Ä–∞–Ω—è—è —Å–º—ã—Å–ª, –Ω–æ –¥–µ–ª–∞—è –∏—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–º–∏. –í—Å–µ–≥–¥–∞ —Å–ª–µ–¥—É–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º —Ç–æ—á–Ω–æ, —à–∞–≥ –∑–∞ —à–∞–≥–æ–º, —á—Ç–æ–±—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±—ã–ª –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã–º –¥–∞–∂–µ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π."
        
        # –í—ã–∑–æ–≤ —Å fallback, max_tokens=600 –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –¥–ª–∏–Ω—ã (Telegram –ª–∏–º–∏—Ç 1024 —Å–∏–º–≤–æ–ª–∞ –Ω–∞ caption)
        result = self._generate_with_fallback(prompt, system_prompt, temperature=self.temperature, max_tokens=600)
        
        if result:
            return result
        else:
            # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª —Å –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–µ–π
            logger.warning("‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback: –ø—Ä–æ—Å—Ç–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞")
            return self._simple_text_modification(original_text)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–ø–∏—Å—ã–≤–∞–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
        return original_text

def _simple_text_modification(self, text: str) -> str:
    """–ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –µ—Å–ª–∏ –≤—Å–µ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""
    # –ü—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª–µ–≥–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ CTA
    modified = f"{text}\n\n{Config.YOUR_BRAND_NAME}"
    return modified

def _build_rewrite_prompt_with_links(self, text: str) -> str:
    """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞ —Å–æ —Å—Å—ã–ª–∫–∞–º–∏"""
    return f"""–ü–µ—Ä–µ–ø–∏—à–∏ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ª—é–±—É—é —Ç–µ–º—É —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª —É–Ω–∏–∫–∞–ª—å–Ω—ã–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–ª –≤–µ—Å—å —Å–º—ã—Å–ª. –¢–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π, –≤–∫–ª—é—á–∞—è –Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Telegram.

–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–ö–°–¢:
{text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø (–≤—ã–ø–æ–ª–Ω—è–π —à–∞–≥ –∑–∞ —à–∞–≥–æ–º):
1. –ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–π–º–∏ –æ—Å–Ω–æ–≤–Ω—É—é –∏–¥–µ—é, —Ñ–∞–∫—Ç—ã, –¥–µ—Ç–∞–ª–∏.
2. –ó–∞–º–µ–Ω–∏ –í–°–ï —Å—Å—ã–ª–∫–∏ (t.me/..., https://..., –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ) –Ω–∞ "{Config.YOUR_LINK}".
3. –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ —Ñ–∞–∫—Ç—ã, –¥–µ—Ç–∞–ª–∏, —Ä–µ–≥–∏–æ–Ω—ã, –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã, –≤—Ä–µ–º—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å.
4. –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∏–ª—å: {Config.CHANNEL_STYLE}.
5. –£–ø–æ–º—è–Ω–∏ "{Config.YOUR_BRAND_NAME}" –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∫–∞–∫ —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –æ–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Å–º—ã—Å–ª—É.
6. –°–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –∂–∏–≤—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º, –Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π —Å—Ä–æ—á–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ.
7. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "–ø–æ –¥–∞–Ω–Ω—ã–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞" - –ø–∏—à–∏ –æ—Ç —Å–≤–æ–µ–≥–æ –ª–∏—Ü–∞.
8. –ù–ï –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ.
9. –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ø–∏—Å–∫–∏ –∏–ª–∏ –∞–±–∑–∞—Ü—ã, —Å–æ—Ö—Ä–∞–Ω–∏ –∏—Ö.
10. ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–û–†–û–¢–ö–ò–ú - –º–∞–∫—Å–∏–º—É–º 800 —Å–∏–º–≤–æ–ª–æ–≤! –ï—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª –¥–ª–∏–Ω–Ω–µ–µ, —Å–æ–∫—Ä–∞—Ç–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏.

–ü–ï–†–ï–ü–ò–°–ê–ù–ù–´–ô –¢–ï–ö–°–¢ (–Ω–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è):"""

def _build_rewrite_prompt_simple(self, text: str) -> str:
    """–°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ —Å—Å—ã–ª–æ–∫"""
    return f"""–ü–µ—Ä–µ–ø–∏—à–∏ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ª—é–±—É—é —Ç–µ–º—É —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω –±—ã–ª —É–Ω–∏–∫–∞–ª—å–Ω—ã–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–ª –≤–µ—Å—å —Å–º—ã—Å–ª. –¢–µ–º–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ª—é–±–æ–π, –≤–∫–ª—é—á–∞—è –Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ Telegram.

–û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–ö–°–¢:
{text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø (–≤—ã–ø–æ–ª–Ω—è–π —à–∞–≥ –∑–∞ —à–∞–≥–æ–º):
1. –ü—Ä–æ—á–∏—Ç–∞–π —Ç–µ–∫—Å—Ç –∏ –ø–æ–π–º–∏ –æ—Å–Ω–æ–≤–Ω—É—é –∏–¥–µ—é, —Ñ–∞–∫—Ç—ã, –¥–µ—Ç–∞–ª–∏.
2. –ü–µ—Ä–µ—Ñ—Ä–∞–∑–∏—Ä—É–π –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –≤—Å–µ —Ñ–∞–∫—Ç—ã, –¥–µ—Ç–∞–ª–∏, —Ä–µ–≥–∏–æ–Ω—ã, –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã, –≤—Ä–µ–º—è, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å.
3. –°–ª–µ–≥–∫–∞ –∏–∑–º–µ–Ω–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏.
4. –ò—Å–ø–æ–ª—å–∑—É–π —Å—Ç–∏–ª—å: {Config.CHANNEL_STYLE}.
5. –£–ø–æ–º—è–Ω–∏ "{Config.YOUR_BRAND_NAME}" –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –∫–∞–∫ —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞, –µ—Å–ª–∏ –æ–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Å–º—ã—Å–ª—É.
6. –°–¥–µ–ª–∞–π —Ç–µ–∫—Å—Ç –Ω–µ–º–Ω–æ–≥–æ –±–æ–ª–µ–µ –∂–∏–≤—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º.
7. –ù–ï –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é –∏–ª–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ.
8. –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É: –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ø–∏—Å–∫–∏ –∏–ª–∏ –∞–±–∑–∞—Ü—ã, —Å–æ—Ö—Ä–∞–Ω–∏ –∏—Ö.
9. ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ö–û–†–û–¢–ö–ò–ú - –º–∞–∫—Å–∏–º—É–º 800 —Å–∏–º–≤–æ–ª–æ–≤! –ï—Å–ª–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª –¥–ª–∏–Ω–Ω–µ–µ, —Å–æ–∫—Ä–∞—Ç–∏ –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á–∞—Å—Ç–∏.

–ü–ï–†–ï–ü–ò–°–ê–ù–ù–´–ô –¢–ï–ö–°–¢ (–Ω–∞—á–Ω–∏ —Å—Ä–∞–∑—É —Å —Ç–µ–∫—Å—Ç–∞, –±–µ–∑ –≤–≤–µ–¥–µ–Ω–∏—è):"""

def check_uniqueness(self, original: str, rewritten: str) -> float:
    """
    –û—Ü–µ–Ω–∏–≤–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–ø–∏—Å–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–ø—Ä–∏–º–µ—Ä–Ω–æ)
    
    Returns:
        –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑–ª–∏—á–∏—è (0-100)
    """
    # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–ª–∏—á–∞—é—â–∏—Ö—Å—è —Å–ª–æ–≤
    original_words = set(original.lower().split())
    rewritten_words = set(rewritten.lower().split())
    
    if not original_words:
        return 0.0
    
    different_words = rewritten_words - original_words
    uniqueness = (len(different_words) / len(original_words)) * 100
    
    return min(uniqueness, 100.0)

def enhance_with_cta(self, text: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –±—Ä–µ–Ω–¥–∞ –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç (–±–µ–∑ CTA)
    
    Args:
        text: –¢–µ–∫—Å—Ç –ø–æ—Å—Ç–∞
        
    Returns:
        –¢–µ–∫—Å—Ç —Å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ–º
    """
    try:
        prompt = f"""–î–æ–±–∞–≤—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ "{Config.YOUR_BRAND_NAME}" –≤ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ —Å–º—ã—Å–ª—É:

–¢–ï–ö–°–¢:
{text}

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –£–ø–æ–º—è–Ω–∏ "{Config.YOUR_BRAND_NAME}" —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ –ª–æ–≥–∏—á–Ω–æ –≤–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è.
2. –ù–ï –¥–æ–±–∞–≤–ª—è–π –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é.
3. –ù–ï –¥–æ–±–∞–≤–ª—è–π —Å—Å—ã–ª–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç.
4. –ú–∞–∫—Å–∏–º—É–º 1 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è.
5. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –≤–ø–∏—Å—ã–≤–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç.

–¢–ï–ö–°–¢ –° –£–ü–û–ú–ò–ù–ê–ù–ò–ï–ú:"""
        
        result = self._generate_with_fallback(prompt, "", 0.5, 500)
        
        if result:
            return result
        else:
            # –ü—Ä–æ—Å—Ç–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –≤—Ä—É—á–Ω—É—é, –µ—Å–ª–∏ –ø–æ–¥—Ö–æ–¥–∏—Ç
            return f"{text} (—Å {Config.YOUR_BRAND_NAME})" if "VPN" in text or "–∑–∞—â–∏—Ç–∞" in text else text
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è: {e}")
        return text

# Singleton instance
_llm_client = None

def get_llm_client() -> LLMClient:
    """–ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä LLM –∫–ª–∏–µ–Ω—Ç–∞"""
    global _llm_client
    if _llm_client is None:
        _llm_client = LLMClient()
    return _llm_client
